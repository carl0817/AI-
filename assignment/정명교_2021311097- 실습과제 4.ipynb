{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfobKjJRIKMC",
        "outputId": "825b779b-27f2-4fcb-e5aa-c906358f8e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 0.712997079\n",
            "Epoch: 0002 cost = 0.430425495\n",
            "Epoch: 0003 cost = 0.384661943\n",
            "Epoch: 0004 cost = 0.361041397\n",
            "Epoch: 0005 cost = 0.346561611\n",
            "Epoch: 0006 cost = 0.335881978\n",
            "Epoch: 0007 cost = 0.328014225\n",
            "Epoch: 0008 cost = 0.321718752\n",
            "Epoch: 0009 cost = 0.316227525\n",
            "Epoch: 0010 cost = 0.312065393\n",
            "Epoch: 0011 cost = 0.308147997\n",
            "Epoch: 0012 cost = 0.304742455\n",
            "Epoch: 0013 cost = 0.302093059\n",
            "Epoch: 0014 cost = 0.299490869\n",
            "Epoch: 0015 cost = 0.296950549\n",
            "Epoch: 0016 cost = 0.295024067\n",
            "Epoch: 0017 cost = 0.292878270\n",
            "Epoch: 0018 cost = 0.291426718\n",
            "Epoch: 0019 cost = 0.289959490\n",
            "Epoch: 0020 cost = 0.288146228\n",
            "Learning finished\n",
            "time : 101.22554731369019\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# parameters\n",
        "training_epochs = 20\n",
        "batch_size = 256\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "# MNIST data image of shape 28 * 28 = 784\n",
        "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
        "\n",
        "start = time.time()  # start time\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = linear(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')\n",
        "print(\"time :\", time.time()-start )  # Q1) Complete the code to print the total execution time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "RtnIw1LOMTAQ",
        "outputId": "fde82541-fbc1-49dc-a726-46c5276548fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8953999876976013\n",
            "Label:  0\n",
            "Prediction:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # Q2) Complete the following code so that read and print one test data of the last 4 digits of your student ID.\n",
        "    # ex. In case of s_id = 2008710991, read and print 0992th test data sample.\n",
        "    r = 2021311097 % 10000\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = linear(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBhihZDe-Taj",
        "outputId": "0536fd00-6644-4203-e4a7-3b75f74971a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning started. It takes sometime.\n",
            "[Epoch:    1] cost = 0.159602523\n",
            "[Epoch:    2] cost = 0.0418291949\n",
            "[Epoch:    3] cost = 0.0294551607\n",
            "[Epoch:    4] cost = 0.0219598711\n",
            "[Epoch:    5] cost = 0.0166420415\n",
            "[Epoch:    6] cost = 0.0141204679\n",
            "[Epoch:    7] cost = 0.0124912476\n",
            "[Epoch:    8] cost = 0.00812436361\n",
            "[Epoch:    9] cost = 0.0109953322\n",
            "[Epoch:   10] cost = 0.00810146518\n",
            "[Epoch:   11] cost = 0.00817844365\n",
            "[Epoch:   12] cost = 0.00586066861\n",
            "[Epoch:   13] cost = 0.0061350544\n",
            "[Epoch:   14] cost = 0.00420009764\n",
            "[Epoch:   15] cost = 0.00631071813\n",
            "Learning Finished!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(0)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "# CNN Model (2 conv layers)\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # Final FC 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # Final FC 7x7x64 inputs -> 10 outputs\n",
        "        self.fc1 = torch.nn.Linear(3 * 3 * 128, 625, bias=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# instantiate CNN model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train my model\n",
        "total_batch = len(data_loader)\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "print('Learning Finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2QYsweQ-VRf",
        "outputId": "f5d251f8-fc12-4e78-dad3-1d75b88c2e83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9884999990463257\n"
          ]
        }
      ],
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai_bu_04.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
